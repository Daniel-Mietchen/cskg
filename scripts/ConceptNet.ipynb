{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConceptNet\n",
    "\n",
    "version 5.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting imports, constants, and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import conceptnet_uri as cn\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION=config.VERSION\n",
    "\n",
    "NODE_COLS=config.nodes_cols\n",
    "EDGE_COLS=config.edges_cols\n",
    "\n",
    "MOWGLI_NS=config.mowgli_ns\n",
    "\n",
    "POS_MAPPING=config.pos_mapping\n",
    "\n",
    "POS_REL=config.has_pos\n",
    "POS_FORM_REL=config.has_pos_form\n",
    "IS_POS_FORM_OF_REL=config.is_pos_form_of\n",
    "WORDNET_SENSE_REL=config.wordnet_sense\n",
    "\n",
    "CUSTOM_DATASET=config.custom_dataset\n",
    "\n",
    "data_source=config.cn_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every=500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_path='../input/conceptnet/conceptnet-en.csv'\n",
    "# OUTPUT FILES\n",
    "output_dir='../output_v%s/conceptnet' % VERSION\n",
    "nodes_file='%s/nodes_v%s.csv' % (output_dir, VERSION)\n",
    "edges_file='%s/edges_raw_v%s.csv' % (output_dir, VERSION)\n",
    "edges_enriched_file='%s/edges_enriched_v%s.csv' % (output_dir, VERSION)\n",
    "edges_full_file='%s/edges_v%s.csv' % (output_dir, VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(cn_path, sep='\\t', header=None, converters={4: json.loads})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['assertion','rel','subj','obj','metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel</th>\n",
       "      <th>subj</th>\n",
       "      <th>obj</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/r/Antonym</td>\n",
       "      <td>/c/en/0/n</td>\n",
       "      <td>/c/en/1</td>\n",
       "      <td>{'dataset': '/d/wiktionary/fr', 'license': 'cc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/r/Antonym</td>\n",
       "      <td>/c/en/12_hour_clock/n</td>\n",
       "      <td>/c/en/24_hour_clock</td>\n",
       "      <td>{'dataset': '/d/wiktionary/en', 'license': 'cc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/r/Antonym</td>\n",
       "      <td>/c/en/24_hour_clock/n</td>\n",
       "      <td>/c/en/12_hour_clock</td>\n",
       "      <td>{'dataset': '/d/wiktionary/en', 'license': 'cc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/r/Antonym</td>\n",
       "      <td>/c/en/5/n</td>\n",
       "      <td>/c/en/3</td>\n",
       "      <td>{'dataset': '/d/wiktionary/en', 'license': 'cc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/r/Antonym</td>\n",
       "      <td>/c/en/a.c/n</td>\n",
       "      <td>/c/en/d.c</td>\n",
       "      <td>{'dataset': '/d/wiktionary/fr', 'license': 'cc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410694</td>\n",
       "      <td>/r/UsedFor</td>\n",
       "      <td>/c/en/zoom_lens</td>\n",
       "      <td>/c/en/procure_better_shot</td>\n",
       "      <td>{'dataset': '/d/conceptnet/4/en', 'license': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410695</td>\n",
       "      <td>/r/UsedFor</td>\n",
       "      <td>/c/en/zoom_lens</td>\n",
       "      <td>/c/en/see_things_bigger</td>\n",
       "      <td>{'dataset': '/d/conceptnet/4/en', 'license': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410696</td>\n",
       "      <td>/r/UsedFor</td>\n",
       "      <td>/c/en/zoom_lens</td>\n",
       "      <td>/c/en/seeing_distant_object_more_closely</td>\n",
       "      <td>{'dataset': '/d/conceptnet/4/en', 'license': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410697</td>\n",
       "      <td>/r/UsedFor</td>\n",
       "      <td>/c/en/zoom_lens</td>\n",
       "      <td>/c/en/take_pictures</td>\n",
       "      <td>{'dataset': '/d/conceptnet/4/en', 'license': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410698</td>\n",
       "      <td>/r/UsedFor</td>\n",
       "      <td>/c/en/zoom_lens</td>\n",
       "      <td>/c/en/varying_camera_focal_point</td>\n",
       "      <td>{'dataset': '/d/conceptnet/4/en', 'license': '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3410699 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                rel                   subj  \\\n",
       "0        /r/Antonym              /c/en/0/n   \n",
       "1        /r/Antonym  /c/en/12_hour_clock/n   \n",
       "2        /r/Antonym  /c/en/24_hour_clock/n   \n",
       "3        /r/Antonym              /c/en/5/n   \n",
       "4        /r/Antonym            /c/en/a.c/n   \n",
       "...             ...                    ...   \n",
       "3410694  /r/UsedFor        /c/en/zoom_lens   \n",
       "3410695  /r/UsedFor        /c/en/zoom_lens   \n",
       "3410696  /r/UsedFor        /c/en/zoom_lens   \n",
       "3410697  /r/UsedFor        /c/en/zoom_lens   \n",
       "3410698  /r/UsedFor        /c/en/zoom_lens   \n",
       "\n",
       "                                              obj  \\\n",
       "0                                         /c/en/1   \n",
       "1                             /c/en/24_hour_clock   \n",
       "2                             /c/en/12_hour_clock   \n",
       "3                                         /c/en/3   \n",
       "4                                       /c/en/d.c   \n",
       "...                                           ...   \n",
       "3410694                 /c/en/procure_better_shot   \n",
       "3410695                   /c/en/see_things_bigger   \n",
       "3410696  /c/en/seeing_distant_object_more_closely   \n",
       "3410697                       /c/en/take_pictures   \n",
       "3410698          /c/en/varying_camera_focal_point   \n",
       "\n",
       "                                                  metadata  \n",
       "0        {'dataset': '/d/wiktionary/fr', 'license': 'cc...  \n",
       "1        {'dataset': '/d/wiktionary/en', 'license': 'cc...  \n",
       "2        {'dataset': '/d/wiktionary/en', 'license': 'cc...  \n",
       "3        {'dataset': '/d/wiktionary/en', 'license': 'cc...  \n",
       "4        {'dataset': '/d/wiktionary/fr', 'license': 'cc...  \n",
       "...                                                    ...  \n",
       "3410694  {'dataset': '/d/conceptnet/4/en', 'license': '...  \n",
       "3410695  {'dataset': '/d/conceptnet/4/en', 'license': '...  \n",
       "3410696  {'dataset': '/d/conceptnet/4/en', 'license': '...  \n",
       "3410697  {'dataset': '/d/conceptnet/4/en', 'license': '...  \n",
       "3410698  {'dataset': '/d/conceptnet/4/en', 'license': '...  \n",
       "\n",
       "[3410699 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['assertion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/d/wiktionary/fr'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['metadata'][0]['dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create nodes.csv and edges.csv\n",
    "\n",
    "Let's first extract the main data into temporary structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed row 0\n",
      "processed row 500000\n",
      "processed row 1000000\n",
      "processed row 1500000\n",
      "processed row 2000000\n",
      "processed row 2500000\n",
      "processed row 3000000\n"
     ]
    }
   ],
   "source": [
    "node_datasets=defaultdict(set)\n",
    "all_edges=[]\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    subj=row['subj']\n",
    "    obj=row['obj']\n",
    "    rel=row['rel']\n",
    "    dataset=row['metadata']['dataset']\n",
    "    weight=row['metadata']['weight']\n",
    "    sentence=''\n",
    "    \n",
    "    node_datasets[subj].add(dataset)\n",
    "    node_datasets[obj].add(dataset)\n",
    "    \n",
    "    other={'dataset': dataset}\n",
    "    edge_data=[subj, rel, obj, data_source, weight, other]\n",
    "    all_edges.append(edge_data)\n",
    "    \n",
    "    if (i%print_every==0): print('processed row', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787272\n",
      "3410699\n"
     ]
    }
   ],
   "source": [
    "print(len(node_datasets))\n",
    "print(len(all_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relation(ns, rel):\n",
    "    return '%s:%s' % (ns, rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tag(uri):\n",
    "    components=cn.split_uri(uri)\n",
    "    if len(components)<4:\n",
    "        return '', ''\n",
    "    else:\n",
    "        raw_pos=components[3]\n",
    "        mapped_pos=create_relation(MOWGLI_NS, POS_MAPPING[raw_pos])\n",
    "        return mapped_pos, raw_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Prepare and store nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes=[]\n",
    "for n, datasets in node_datasets.items():\n",
    "    label=cn.uri_to_label(n)\n",
    "    aliases_list=[]\n",
    "    aliases=','.join(aliases_list)\n",
    "    mapped_pos, raw_pos=get_pos_tag(n)\n",
    "    other={'datasets': list(datasets)}\n",
    "    col=[n, label, aliases, raw_pos, data_source, other]\n",
    "    all_nodes.append(col)\n",
    "    \n",
    "for raw_pos, mapped_pos in POS_MAPPING.items():\n",
    "    mowgli_pos=create_relation(MOWGLI_NS, mapped_pos)\n",
    "    col=[mowgli_pos, raw_pos, mapped_pos, '', '', {\"datasets\": [CUSTOM_DATASET]}]\n",
    "    all_nodes.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1787276"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = pd.DataFrame(all_nodes, columns = NODE_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['n', '', 'r', 'a', 'v'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df['pos'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df.sort_values('id').to_csv(nodes_file, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Enrich and store edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = pd.DataFrame(all_edges, columns = EDGE_COLS)\n",
    "edges_df.sort_values(by=['subject', 'predicate','object']).to_csv(edges_file, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed row 0\n",
      "processed row 500000\n",
      "processed row 1000000\n",
      "processed row 1500000\n"
     ]
    }
   ],
   "source": [
    "all_edges_enriched=copy.deepcopy(all_edges)\n",
    "other={'dataset': CUSTOM_DATASET}\n",
    "for i, row in nodes_df.iterrows():\n",
    "    \n",
    "    node_id=row['id']\n",
    "    components=cn.split_uri(node_id)\n",
    "    \n",
    "    if len(components)==4:\n",
    "        # add POS relations\n",
    "        mapped_pos, raw_pos = get_pos_tag(node_id)\n",
    "        edge=[node_id, create_relation(MOWGLI_NS, POS_REL), mapped_pos, data_source, \"1.0\", other]\n",
    "        all_edges_enriched.append(edge)\n",
    "        \n",
    "        le_node='/%s' % '/'.join(components[:3])\n",
    "        if le_node in node_datasets.keys():\n",
    "            # add pos-form relations (both-ways)\n",
    "            edge=[le_node, create_relation(MOWGLI_NS, POS_FORM_REL), node_id, data_source, \"1.0\", other]\n",
    "            all_edges_enriched.append(edge)\n",
    "\n",
    "            edge=[node_id, create_relation(MOWGLI_NS, IS_POS_FORM_OF_REL), le_node, data_source, \"1.0\", other]\n",
    "            all_edges_enriched.append(edge)\n",
    "        \n",
    "    elif len(components)>=5 and components[4]=='wn':\n",
    "        # add OMW relations\n",
    "        pos_node='/%s' % '/'.join(components[:4])\n",
    "        if pos_node in node_datasets.keys():\n",
    "            edge=[pos_node, create_relation(MOWGLI_NS, WORDNET_SENSE_REL), node_id, data_source, \"1.0\", other]\n",
    "            all_edges_enriched.append(edge)\n",
    "    \n",
    "    if (i%print_every==0): print('processed row', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_enriched_df = pd.DataFrame(all_edges_enriched, columns = EDGE_COLS)\n",
    "edges_enriched_df.sort_values(by=['subject', 'predicate','object']).to_csv(edges_enriched_file, \n",
    "                                                                           index=False, \n",
    "                                                                           sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3410699"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5282888"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_edges_enriched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Complement missing symmetric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipilievski/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/r/Antonym 19066\n",
      "Index(['subject', 'predicate', 'object', 'datasource', 'weight', 'other',\n",
      "       '_merge'],\n",
      "      dtype='object')\n",
      "18788\n",
      "\n",
      "/r/DistinctFrom 3315\n",
      "Index(['subject', 'predicate', 'object', 'datasource', 'weight', 'other',\n",
      "       '_merge'],\n",
      "      dtype='object')\n",
      "3251\n",
      "\n",
      "/r/EtymologicallyRelatedTo 32075\n",
      "Index(['subject', 'predicate', 'object', 'datasource', 'weight', 'other',\n",
      "       '_merge'],\n",
      "      dtype='object')\n",
      "29999\n",
      "\n",
      "/r/LocatedNear 49\n",
      "Index(['subject', 'predicate', 'object', 'datasource', 'weight', 'other',\n",
      "       '_merge'],\n",
      "      dtype='object')\n",
      "49\n",
      "\n",
      "/r/RelatedTo 1703582\n",
      "Index(['subject', 'predicate', 'object', 'datasource', 'weight', 'other',\n",
      "       '_merge'],\n",
      "      dtype='object')\n",
      "1690482\n",
      "\n",
      "/r/SimilarTo 30280\n",
      "Index(['subject', 'predicate', 'object', 'datasource', 'weight', 'other',\n",
      "       '_merge'],\n",
      "      dtype='object')\n",
      "8830\n",
      "\n",
      "/r/Synonym 222156\n",
      "Index(['subject', 'predicate', 'object', 'datasource', 'weight', 'other',\n",
      "       '_merge'],\n",
      "      dtype='object')\n",
      "177035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_difs=[edges_enriched_df]\n",
    "for sym_rel in config.symmetric_rels:\n",
    "    #if sym_rel!='/r/LocatedNear': continue\n",
    "        \n",
    "    sub_df=edges_enriched_df[edges_enriched_df.predicate==sym_rel]\n",
    "    sub_df['other']=\"\"\n",
    "    print(sym_rel, len(sub_df))\n",
    "    \n",
    "    so_df=sub_df[EDGE_COLS]\n",
    "    \n",
    "    os_df=sub_df[['object', 'predicate', 'subject', 'datasource', 'weight', 'other']]\n",
    "    os_df.columns=EDGE_COLS\n",
    "    \n",
    "    the_diff=os_df.merge(so_df,indicator = True, \n",
    "                         how='left').loc[lambda x : x['_merge']!='both']\n",
    "    \n",
    "    the_diff['other']=json.dumps({'dataset': CUSTOM_DATASET})\n",
    "    the_diff['other']=the_diff['other'].apply(json.loads)\n",
    "    \n",
    "    print(the_diff.columns)\n",
    "    \n",
    "    print(len(the_diff))\n",
    "    print()\n",
    "    all_difs.append(the_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipilievski/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_data=pd.concat(all_difs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'predicate', 'object', 'datasource', 'weight', 'other'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=all_data[EDGE_COLS]\n",
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.sort_values(by=['subject', 'predicate','object']).to_csv(edges_full_file, \n",
    "                                                                  index=False, \n",
    "                                                                  sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7211322"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
